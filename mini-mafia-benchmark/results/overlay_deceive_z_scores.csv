Model,ShortPrompt Avg Z,ShortPrompt Z Err,Article Avg Z,Article Z Err,ShortPrompt Round8 Avg Z,ShortPrompt Round8 Z Err,ShortPrompt exp(z),ShortPrompt exp Err,Article exp(z),Article exp Err,ShortPrompt Round8 exp(z),ShortPrompt Round8 exp Err
Llama 3.1 8B Instruct,-0.3109,0.2955,-1.1296,0.2165,-0.5517,0.1812,0.7328,0.2166,0.3232,0.0700,0.5760,0.1044
Qwen2.5 7B Instruct,-0.9788,0.2835,-0.9629,0.2118,-0.6180,0.1702,0.3758,0.1065,0.3818,0.0809,0.5390,0.0917
GPT-4.1 Mini,0.3948,0.3013,-0.5504,0.2290,-0.6704,0.1934,1.4841,0.4472,0.5767,0.1320,0.5115,0.0989
Mistral 7B Instruct,-0.6078,0.2852,-0.3299,0.2241,-0.5232,0.1899,0.5445,0.1553,0.7190,0.1612,0.5926,0.1125
GPT-5 Mini,0.0155,0.3053,-0.2678,0.2364,0.5181,0.2114,1.0156,0.3101,0.7651,0.1809,1.6789,0.3549
Claude Sonnet 4,0.0937,0.3153,0.6198,0.2545,0.0583,0.3126,1.0983,0.3463,1.8586,0.4730,1.0600,0.3314
Grok 3 Mini,0.8526,0.3036,0.7026,0.2408,0.9597,0.2020,2.3457,0.7122,2.0190,0.4862,2.6108,0.5273
Claude Opus 4.1,0.3218,0.3126,0.7867,0.2565,0.5526,0.2312,1.3797,0.4312,2.1961,0.5633,1.7378,0.4018
DeepSeek V3.1,0.2190,0.3068,1.1314,0.2645,0.2744,0.2002,1.2448,0.3819,3.1001,0.8201,1.3158,0.2634
