Model,Deceive_Z,Deceive_Z_Error,Detect_Z,Detect_Z_Error,Disclose_Z,Disclose_Z_Error
Claude Opus 4.1,0.7872290797557879,0.2681660522662489,0.6812817361103655,0.19310837342075918,0.6507756228688782,0.1271408725386973
Claude Sonnet 4,0.6204953329136905,0.2665640157037964,-0.7411908007351926,0.21478524134820304,0.5561728043973175,0.12972839065363034
DeepSeek V3.1,1.139683482794273,0.2762709304762839,0.7546416654033756,0.19908560152996696,0.5165417924178414,0.12994800393627098
GPT-4.1 Mini,-0.6044252580554833,0.24009865325540533,-0.44660737648618387,0.21457030134493643,0.40064718711418673,0.13281362860010715
GPT-5 Mini,-0.31486349688142207,0.24731617200951464,-0.40997778123458256,0.21465126088351863,0.7278029631156375,0.12684868402363803
Gemini 2.5 Flash Lite,0.2673027829140742,0.2568603910259334,-0.008922666366657417,0.213706367090784,0.09224067250937493,0.13364339165607814
Grok 3 Mini,0.7154456008835959,0.2523689926302556,1.9021900547507697,0.17271063924233232,0.6435650511231075,0.12720256878423564
Llama 3.1 8B Instruct,-1.2152455942181022,0.2267764921667695,-0.608512137640042,0.21688759840996324,-2.278854164352299,0.11909024039784973
Mistral 7B Instruct,-0.370655197293771,0.23498059118953757,-0.6620382020172126,0.21658662112686983,-0.638889944946993,0.14007484844292384
Qwen2.5 7B Instruct,-1.0249667328126446,0.2231706286598003,-0.46086449178464317,0.21498977142943562,-0.6700019842470507,0.136502171017081
