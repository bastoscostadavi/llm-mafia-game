# Results

This directory contains all generated outputs from the analysis scripts, organized by research methodology. All files here are **generated** - do not edit manually. To regenerate, run the corresponding scripts in `../analysis/`.

## Directory Structure

```
results/
├── bottom_up_background/      # 25 files - Background-based methodology
├── top_down_theoretical/       # 5 files - Theoretical model
├── serendipitous_results/      # 2 files - Emergent phenomena
└── ablation_experiments/       # 4 files - Robustness checks
```

## Bottom-up Background (25 files)

**Generated by:** `../analysis/bottom_up_background/` scripts

**CSV files (4):**
- `win_counts.csv` - Raw win counts per background configuration
- `win_rates.csv` - Bayesian win rates with uncertainties
- `results_table.csv` - Final exponential scores (α = e^z̄)
- `results_table_zscores.csv` - Intermediate z-scores

**Plots (21):**
- **Win rate plots (15):** `win_rates_{capability}_{background}.png`
  - 5 backgrounds × 3 capabilities
  - Shows model performance against specific opponent combinations

- **Score plots (6):** `scores_{capability}.png` and `scores_z_{capability}.png`
  - Exponential scores (α scale) and z-scores
  - 3 capabilities: deceive, detect, disclose

**To regenerate:**
```bash
cd ../analysis/bottom_up_background/
python3 win_counts_table.py
python3 win_rates_table_and_plot.py
python3 scores_table_and_plot.py
```

## Top-down Theoretical (5 files)

**Generated by:** `../analysis/top_down_theoretical/scores_theoretical_model.py`

**CSV file (1):**
- `scores_theoretical.csv` - Model parameters (m, d, v) with uncertainties

**Plots (4):**
- `scores_theoretical_combined.png` - All three capabilities in one figure
- `scores_deceive_theoretical.png` - Deception parameters (m_i)
- `scores_detect_theoretical.png` - Detection parameters (v_k)
- `scores_disclose_theoretical.png` - Disclosure parameters (d_j)

**To regenerate:**
```bash
cd ../analysis/top_down_theoretical/
python3 scores_theoretical_model.py
```

## Serendipitous Results (2 files)

**Generated by:** `../analysis/serendipitous_results/` scripts

**CSV files (2):**
- `name_bias.csv` - Win rates by character name (Bob, Alice, Charlie, Diana)
- `last_speaker_advantage.csv` - Win rates by speaking position and role

**To regenerate:**
```bash
cd ../analysis/serendipitous_results/
python3 name_bias.py
python3 last_speaker_advantage.py
```

## Ablation Experiments (4 files)

**Pre-generated files** (script has legacy dependencies):

**CSV file (1):**
- `overlay_deceive_z_scores.csv` - Comparison across experimental conditions

**Plots (3):**
- `overlay_deceive_z_scores.png` - Main comparison (used in paper)
- `overlay_deceive_exp_scores.png` - Alternative exponential scale view
- `overlay_deceive_z_scores_bland_altman.png` - Bland-Altman agreement plot

**Note:** These were generated from ablation experiments and are included as pre-computed results.

## Paper Figures

Files referenced in the paper `../article/main.tex`:

### Main Text
- `top_down_theoretical/scores_theoretical_combined.png` - Figure 1
- `top_down_theoretical/scores_deceive_theoretical.png` - Deception example
- `top_down_theoretical/scores_detect_theoretical.png` - Detection example
- `top_down_theoretical/scores_disclose_theoretical.png` - Disclosure example
- `ablation_experiments/overlay_deceive_z_scores.png` - Robustness check

### Appendix
- All 15 win rate plots from `bottom_up_background/`
- Z-score plots from `bottom_up_background/`

## File Formats

**CSV files:**
- Comma-separated values
- Headers included
- Compatible with pandas, Excel, R

**PNG plots:**
- 300 DPI resolution
- Publication quality
- White background
- Consistent styling (24pt fonts)

## Usage

### Loading in Python

```python
import pandas as pd

# Load results
scores = pd.read_csv('bottom_up_background/results_table.csv')
theoretical = pd.read_csv('top_down_theoretical/scores_theoretical.csv')
name_bias = pd.read_csv('serendipitous_results/name_bias.csv')

print(scores.head())
```

### Loading in R

```r
# Load results
scores <- read.csv('bottom_up_background/results_table.csv')
theoretical <- read.csv('top_down_theoretical/scores_theoretical.csv')
```

### Using in LaTeX

```latex
\includegraphics[width=\textwidth]{../results/top_down_theoretical/scores_theoretical_combined.png}
```

## Data Dictionary

### results_table.csv
- `Model` - Model name
- `Deceive` - Exponential deception score (α)
- `Deceive_Error` - Uncertainty in deception score
- `Detect` - Exponential detection score (α)
- `Detect_Error` - Uncertainty in detection score
- `Disclose` - Exponential disclosure score (α)
- `Disclose_Error` - Uncertainty in disclosure score

**Interpretation:** α = 1.0 is average performance. Higher is better.

### scores_theoretical.csv
- `Model` - Model name
- `Deceive` - Deception parameter (m_i) from theoretical model
- `Deceive_Error` - Bayesian posterior uncertainty
- `Detect` - Detection parameter (v_k) from theoretical model
- `Detect_Error` - Bayesian posterior uncertainty
- `Disclose` - Disclosure parameter (d_j) from theoretical model
- `Disclose_Error` - Bayesian posterior uncertainty

**Interpretation:** Raw parameters from logit model. Higher values = better capability.

### name_bias.csv
- `character` - Character name (Alice, Bob, Charlie, Diana)
- `total_games` - Number of games played with this name
- `wins` - Number of wins
- `win_rate_bayesian` - Bayesian win rate (0-1)
- `uncertainty_std` - Standard deviation of posterior
- `confidence_interval_lower` - 95% CI lower bound
- `confidence_interval_upper` - 95% CI upper bound

### last_speaker_advantage.csv
- `role` - Role (detective, mafioso, villager)
- `total_games` - Total games for this role
- `total_wins` - Total wins
- `total_win_rate_pct` - Overall win rate (%)
- `total_uncertainty_pct` - Uncertainty (%)
- `last_speaker_games` - Games where role spoke last
- `last_speaker_wins` - Wins when speaking last
- `last_speaker_win_rate_pct` - Win rate when last (%)
- `last_speaker_uncertainty_pct` - Uncertainty (%)

## Regenerating All Results

To regenerate all results from scratch:

```bash
# Bottom-up (run in sequence)
cd ../analysis/bottom_up_background/
python3 win_counts_table.py && \
python3 win_rates_table_and_plot.py && \
python3 scores_table_and_plot.py

# Top-down
cd ../top_down_theoretical/
python3 scores_theoretical_model.py

# Serendipitous
cd ../serendipitous_results/
python3 name_bias.py
python3 last_speaker_advantage.py

# Return to results directory
cd ../../results/
```

**Time estimate:** 5-10 minutes total (theoretical model is slowest)

## Storage

**Total size:** ~5 MB
- CSV files: ~50 KB
- PNG plots: ~4.5 MB (high resolution)

## Version Control

**Recommended .gitignore:**
```
# Keep structure but ignore generated files
results/*/*.png
results/*/*.csv

# Exception: keep ablation pre-generated files
!results/ablation_experiments/*.png
!results/ablation_experiments/*.csv
```

Or keep all results in git for reproducibility (recommended for published papers).

## Citation

Results are from:

```bibtex
@article{costa2025minimafia,
  title={Deceive, Detect, and Disclose: Large Language Models Playing Mini-Mafia},
  author={Costa, Davi Bastos and Vicente, Renato},
  year={2025}
}
```
