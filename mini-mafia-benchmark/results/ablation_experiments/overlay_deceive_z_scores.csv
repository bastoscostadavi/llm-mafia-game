Model,ShortPrompt Avg Z,ShortPrompt Z Err,Article Avg Z,Article Z Err,ShortPrompt Round8 Avg Z,ShortPrompt Round8 Z Err,ShortPrompt exp(z),ShortPrompt exp Err,Article exp(z),Article exp Err,ShortPrompt Round8 exp(z),ShortPrompt Round8 exp Err
Llama 3.1 8B Instruct,-0.3109,0.2955,-1.2152,0.2268,-0.5517,0.1812,0.7328,0.2166,0.2966,0.0673,0.5760,0.1044
Qwen2.5 7B Instruct,-0.9788,0.2835,-1.0250,0.2232,-0.6180,0.1702,0.3758,0.1065,0.3588,0.0801,0.5390,0.0917
GPT-4.1 Mini,0.3948,0.3013,-0.6044,0.2401,-0.6704,0.1934,1.4841,0.4472,0.5464,0.1312,0.5115,0.0989
Mistral 7B Instruct,-0.6078,0.2852,-0.3707,0.2350,-0.5232,0.1899,0.5445,0.1553,0.6903,0.1622,0.5926,0.1125
GPT-5 Mini,0.0155,0.3053,-0.3149,0.2473,0.5181,0.2114,1.0156,0.3101,0.7299,0.1805,1.6789,0.3549
Claude Sonnet 4,0.0937,0.3153,0.6205,0.2666,0.0583,0.3126,1.0983,0.3463,1.8598,0.4958,1.0600,0.3314
Grok 3 Mini,0.8526,0.3036,0.7154,0.2524,0.9597,0.2020,2.3457,0.7122,2.0451,0.5161,2.6108,0.5273
Claude Opus 4.1,0.3218,0.3126,0.7872,0.2682,0.5526,0.2312,1.3797,0.4312,2.1973,0.5892,1.7378,0.4018
DeepSeek V3.1,0.2190,0.3068,1.1397,0.2763,0.2744,0.2002,1.2448,0.3819,3.1258,0.8636,1.3158,0.2634
