#!/usr/bin/env python3
"""
Z-Score Aggregated Benchmark Plot Generator

Creates standardized performance plots by:
1. Loading data from JSON files generated by create_benchmark_plots.py  
2. Computing z-scores for each model relative to background mean/std
3. Aggregating z-scores across all backgrounds for each behavior type
4. Creating final benchmark plots with standardized scores

Behavior types:
- Deceive: mafioso_*.json files (evil win rates)
- Detect: detective_*.json files (good win rates) 
- Disclose: villager_*.json files (good win rates)
"""

import json
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from collections import defaultdict
import os
from matplotlib.offsetbox import OffsetImage, AnnotationBbox
from PIL import Image

def load_company_logo(company, size=(40, 40)):
    """Load actual company logos from the logos folder"""
    # Map company names to logo filenames  
    logo_files = {
        "OpenAI": "openai.png",
        "X": "xai.png",
        "Mistral AI": "mistral.png", 
        "Meta": "meta.png",
        "Alibaba": "baba.png",
        "Anthropic": "anthropic.png",
        "DeepMind": "deepmind.png",
        "DeepSeek": "deepseek.png",
        "Google": "deepmind.png"  # Use DeepMind logo for Google since they're the same company
    }
    
    try:
        logo_path = f"logos/{logo_files[company]}"
        if os.path.exists(logo_path):
            # Load and resize the actual logo
            img = Image.open(logo_path)
            
            # Convert to RGBA if needed
            if img.mode != 'RGBA':
                img = img.convert('RGBA')
            
            # Resize maintaining aspect ratio
            img.thumbnail(size, Image.Resampling.LANCZOS)
            
            # Create new image with transparent background
            new_img = Image.new('RGBA', size, (255, 255, 255, 0))
            
            # Center the logo
            x = (size[0] - img.width) // 2
            y = (size[1] - img.height) // 2
            new_img.paste(img, (x, y), img if img.mode == 'RGBA' else None)
            
            return np.array(new_img)
        else:
            print(f"Logo file not found: {logo_path}")
            return None
            
    except Exception as e:
        print(f"Error loading logo for {company}: {e}")
        return None

def load_data_files(behavior_type, exclude_mistral=False):
    """Load all JSON data files for a given behavior type"""
    pattern = f"{behavior_type}_*_data.json"
    data_files = list(Path(".").glob(pattern))
    
    if not data_files:
        raise FileNotFoundError(f"No data files found for pattern: {pattern}")
    
    datasets = []
    for file_path in sorted(data_files):
        with open(file_path, 'r') as f:
            data = json.load(f)
            
            # Skip Mistral background if requested
            if exclude_mistral and 'mistral' in data['background'].lower():
                continue
                
            datasets.append({
                'filename': file_path.name,
                'background': data['background'],
                'models': data['models'],
                'win_rates': data['win_rates'],
                'errors': data['errors'],
                'companies': data['companies']
            })
    
    return datasets

def compute_z_scores(datasets):
    """Compute z-scores for each model across all backgrounds"""
    # Collect all z-scores for each model
    model_z_scores = defaultdict(list)
    model_companies = {}  # Store company mapping
    
    for dataset in datasets:
        models = dataset['models']
        win_rates = np.array(dataset['win_rates'])
        errors = np.array(dataset['errors'])
        companies = dataset['companies']
        
        # Store company info for each model
        for model, company in zip(models, companies):
            model_companies[model] = company
        
        # Compute mean and std across all models in this background
        mean_rate = np.mean(win_rates)
        std_rate = np.std(win_rates, ddof=1)  # Sample standard deviation
        
        if std_rate == 0:
            print(f"Warning: Zero std deviation for background {dataset['background']}, skipping")
            continue
        
        # Compute z-scores for each model
        z_scores = (win_rates - mean_rate) / std_rate
        
        # Store z-scores by model
        for model, z_score in zip(models, z_scores):
            model_z_scores[model].append(z_score)
    
    return model_z_scores, model_companies

def aggregate_z_scores(model_z_scores):
    """Aggregate z-scores across backgrounds and compute uncertainties"""
    aggregated_results = {}
    
    for model, z_scores in model_z_scores.items():
        z_array = np.array(z_scores)
        
        # Aggregate: mean z-score across backgrounds
        mean_z_score = np.mean(z_array)
        
        # Uncertainty: standard error of the mean
        sem_z_score = np.std(z_array, ddof=1) / np.sqrt(len(z_array)) if len(z_array) > 1 else 0
        
        aggregated_results[model] = {
            'mean_z_score': mean_z_score,
            'sem_z_score': sem_z_score,
            'n_backgrounds': len(z_array)
        }
    
    return aggregated_results

def create_zscore_plot(aggregated_results, model_companies, behavior_type, filename):
    """Create horizontal bar plot with z-scores"""
    # Use non-interactive backend
    plt.ioff()
    
    # Set font size to match existing plots
    plt.rcParams.update({
        'font.size': 24,
        'axes.labelsize': 24,
        'axes.titlesize': 24,
        'xtick.labelsize': 24,
        'ytick.labelsize': 24,
        'legend.fontsize': 24,
        'figure.titlesize': 24
    })
    
    # Sort models by mean z-score (ascending) so best performer appears at top of plot
    sorted_models = sorted(aggregated_results.keys(), 
                          key=lambda x: aggregated_results[x]['mean_z_score'], 
                          reverse=False)
    
    # Extract data for plotting (reversed order so highest scores appear at top)
    models = sorted_models
    z_scores = [aggregated_results[model]['mean_z_score'] for model in models]
    z_errors = [aggregated_results[model]['sem_z_score'] for model in models]
    companies = [model_companies.get(model, 'Unknown') for model in models]
    
    fig, ax = plt.subplots(figsize=(14, 7))
    
    y_positions = range(len(models))
    
    # Create bars - use neutral color for z-scores
    bars = ax.barh(y_positions, z_scores, xerr=z_errors, 
                   color='#4A90E2', alpha=0.8, height=0.6,
                   error_kw={'capsize': 5, 'capthick': 2})
    
    # Add model names and values on the right side of bars
    for i, (model, z_score, z_error) in enumerate(zip(models, z_scores, z_errors)):
        ax.text(max(z_score + z_error + 0.1, 0.1), i, 
                f'{model}: {z_score:.2f} Â± {z_error:.2f}', 
                ha='left', va='center', fontweight='bold', fontsize=24)
    
    # Add company logos on the left
    logo_x_pos = min(min(z_scores) - 0.5, -0.8)  # Position logos to the left
    for i, company in enumerate(companies):
        logo_img = load_company_logo(company, size=(40, 40))
        if logo_img is not None:
            try:
                imagebox = OffsetImage(logo_img, zoom=0.8)
                ab = AnnotationBbox(imagebox, (logo_x_pos, i), frameon=False, 
                                  xycoords='data', boxcoords="data")
                ax.add_artist(ab)
            except Exception as e:
                print(f"Failed to add logo for {company}: {e}")
                # Fallback to company initial
                ax.text(logo_x_pos, i, company[0], ha='center', va='center', 
                        fontweight='bold', fontsize=24, color='black',
                        bbox=dict(boxstyle="circle,pad=0.3", facecolor='lightgray'))
        else:
            # Fallback to company initial
            ax.text(logo_x_pos, i, company[0], ha='center', va='center', 
                    fontweight='bold', fontsize=24, color='black',
                    bbox=dict(boxstyle="circle,pad=0.3", facecolor='lightgray'))
    
    # Set axis labels based on behavior type
    behavior_labels = {
        'Deceive': 'Deceive Score',
        'Detect': 'Detect Score', 
        'Disclose': 'Disclose Score'
    }
    xlabel = behavior_labels.get(behavior_type, 'Performance Score')
    ax.set_xlabel(xlabel, fontsize=24, fontweight='bold')
    ax.set_yticks([])  # Remove y-axis labels
    
    # Set x-axis limits with some padding
    x_min = min(min(z_scores) - max(z_errors) - 0.5, logo_x_pos - 0.3)
    x_max = max(max(z_scores) + max(z_errors) + 0.5, 2.0)
    ax.set_xlim(x_min, x_max)
    
    # Add vertical line at z=0
    ax.axvline(x=0, color='gray', alpha=0.5, linewidth=1, linestyle='--')
    
    # Add custom grid lines
    for x in np.arange(-2, 3, 0.5):
        if x != 0:  # Don't double-draw the zero line
            ax.axvline(x=x, color='gray', alpha=0.2, linewidth=0.5)
    
    # Hide all spines except bottom
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_color('black')
    ax.spines['bottom'].set_linewidth(0.8)
    
    plt.tight_layout()
    plt.savefig(filename, dpi=300, bbox_inches='tight', 
                facecolor='white', edgecolor='none')
    plt.close()
    print(f"Z-score plot saved as {filename}")
    
    # Return summary statistics
    return {
        'models': models,
        'z_scores': z_scores,
        'z_errors': z_errors,
        'n_models': len(models)
    }

def main():
    """Generate aggregated z-score plots for all behavior types"""
    behavior_types = {
        'mafioso': {'name': 'Deceive', 'description': 'Mafioso performance across backgrounds'},
        'detective': {'name': 'Disclose', 'description': 'Detective performance across backgrounds'},
        'villager': {'name': 'Detect', 'description': 'Villager performance across backgrounds'}
    }
    
    # Create plots with all backgrounds
    print("ð Creating aggregated z-score benchmark plots (all backgrounds)...")
    
    for behavior_key, behavior_info in behavior_types.items():
        print(f"\nð Processing {behavior_info['name']} ({behavior_key}) data...")
        
        try:
            # Load data files
            datasets = load_data_files(behavior_key, exclude_mistral=False)
            print(f"   Loaded {len(datasets)} background datasets")
            
            # Compute z-scores
            model_z_scores, model_companies = compute_z_scores(datasets)
            print(f"   Computed z-scores for {len(model_z_scores)} models")
            
            # Aggregate across backgrounds
            aggregated_results = aggregate_z_scores(model_z_scores)
            print(f"   Aggregated results across backgrounds")
            
            # Create plot
            filename = f"{behavior_key}_score_benchmark.png"
            summary = create_zscore_plot(aggregated_results, model_companies, 
                                       behavior_info['name'], filename)
            
            # Print summary
            print(f"   ð Created plot with {summary['n_models']} models")
            print(f"   ð Top performer: {summary['models'][0]} (z-score: {summary['z_scores'][0]:.2f})")
            
        except Exception as e:
            print(f"   â Error processing {behavior_key}: {e}")
            continue
    
    # Create plots excluding Mistral background
    print("\nð Creating aggregated z-score benchmark plots (excluding Mistral background)...")
    
    for behavior_key, behavior_info in behavior_types.items():
        print(f"\nð Processing {behavior_info['name']} ({behavior_key}) data (no Mistral)...")
        
        try:
            # Load data files excluding Mistral
            datasets = load_data_files(behavior_key, exclude_mistral=True)
            print(f"   Loaded {len(datasets)} background datasets (excluding Mistral)")
            
            # Compute z-scores
            model_z_scores, model_companies = compute_z_scores(datasets)
            print(f"   Computed z-scores for {len(model_z_scores)} models")
            
            # Aggregate across backgrounds
            aggregated_results = aggregate_z_scores(model_z_scores)
            print(f"   Aggregated results across backgrounds")
            
            # Create plot
            filename = f"{behavior_key}_score_benchmark_no_mistral.png"
            summary = create_zscore_plot(aggregated_results, model_companies, 
                                       behavior_info['name'], filename)
            
            # Print summary
            print(f"   ð Created plot with {summary['n_models']} models")
            print(f"   ð Top performer: {summary['models'][0]} (z-score: {summary['z_scores'][0]:.2f})")
            
        except Exception as e:
            print(f"   â Error processing {behavior_key}: {e}")
            continue
    
    print("\nâ Z-score aggregation complete!")
    print("ð Generated files:")
    for behavior_key in behavior_types.keys():
        filename = f"{behavior_key}_score_benchmark.png"
        filename_no_mistral = f"{behavior_key}_score_benchmark_no_mistral.png"
        if os.path.exists(filename):
            print(f"   - {filename}")
        if os.path.exists(filename_no_mistral):
            print(f"   - {filename_no_mistral}")

if __name__ == "__main__":
    main()